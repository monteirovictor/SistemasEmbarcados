# -*- coding: utf-8 -*-
"""Lista3-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lp9PseZWYnaldE8MMWOaHif9owCbFhBh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from prettytable import PrettyTable
from collections import Counter


# Entrada e Organização de Dados

df= pd.read_csv("/content/drive/MyDrive/python/Dados.csv", names=['time','x','y','z','index'])

vetor=np.array(sorted(df['x']))

vetory=np.array(sorted(df['y']))

data=[vetor,vetory]

#Medidas Estátisticas

media=np.mean(vetor)
mediana=np.median(vetor)
variancia=np.var(vetor)
desviopadrao=np.std(vetor)
coenficienteVariacao=(vetor.std()/vetor.mean())*100
primeiroQuartil=np.percentile(vetor,25)
segundoQuartil=np.percentile(vetor,50)
terceiroQuartil=np.percentile(vetor,75)
amplitudeInterquatilica=terceiroQuartil-primeiroQuartil

mediay=np.mean(vetory)
medianay=np.median(vetory)
varianciay=np.var(vetory)
desviopadraoy=np.std(vetory)
coenficienteVariacaoy=(vetory.std()/vetory.mean())*100
primeiroQuartily=np.percentile(vetory,25)
segundoQuartily=np.percentile(vetory,50)
terceiroQuartily=np.percentile(vetory,75)
amplitudeInterquatilicay=terceiroQuartily-primeiroQuartily

#Exibição em Tabela das informações obtidas pelo numpy 

print("\t\t\tExploração Estatística\n")
tabela = PrettyTable()
tabela.add_column('Medidas Estatísticas', ["Media", "Mediana", "Variancia", 
"Desvio Padrão", "Coeficiente de Variação", "Q1", "Q2","Q3","AI"])
tabela.add_column('X', [media, mediana,variancia, desviopadrao, 
coenficienteVariacao,primeiroQuartil,segundoQuartil,terceiroQuartil,amplitudeInterquatilica])
tabela.add_column('Y', [mediay, medianay,varianciay, desviopadraoy, 
coenficienteVariacaoy,primeiroQuartily,segundoQuartily,terceiroQuartily,amplitudeInterquatilicay])
print(tabela)

#Gráfico Boxplot, usando as informações de X,Y
print("\n\t\t\tBoxplot")
fig = plt.figure(figsize =(10, 7))
plt.boxplot(data)
plt.show()

# Percentual de Dados Duplicados de X

print("\n\nPercentual de Dados Duplicados em X\n")

repeticoes = Counter(vetor)
print(repeticoes)


#Calcular porcentagem das repeticoes

t = len(vetor) #Quantidade de dados informada na entrada
'''Utilização do Counter "repeticoes" para gerar uma lista
com todas as porcentagens obtidas no map.
repeticoes[x] retorna o valor da chave x no dicionario.'''
porcentagem = list(map(lambda x: repeticoes[x]*100/t, repeticoes))

print(porcentagem)

#prova real
print("Prova Real x->",np.sum(porcentagem))

# Percentual de Dados Duplicados de y

print("\n\nPercentual de Dados Duplicados em Y\n")

rep = Counter(vetory)
print(rep)

#Calcular porcentagem das repeticoes

ty = len(vetory) #Quantidade de dados informada na entrada
'''Utilização do Counter "repeticoes" para gerar uma lista
com todas as porcentagens obtidas no map.
repeticoes[x] retorna o valor da chave x no dicionario.'''
porc = list(map(lambda x: rep[x]*100/ty, rep))

print(porc)

#prova real
print("Prova Real y->",np.sum(porc))

#Amostra

print("\n\t Amostragem Sistemática")

# Selecionado um registro aleatório entre os valores de 0 a 10:
semente = np.random.choice(10, 1)

# Gerando um array que inicia em 0 e termina em 100 com um intervalo de 7:
indices = np.arange(0,100,semente)

amostra = df.loc[indices,:]
print(amostra)

#Questão 2 

Para a validação das informções obtidas, existe duas técnicas utilizadas para 
para classificar. A técnica FAR, cuja ideia é identificar quando um usuario 
não autorizado é confundido com um usuário legítimo. O método FRR tem o
propósito de medir a probabilidade de classificar um usuário autorizado como 
não autorizado. Dessa forma reduzindo a uma taxa de erro de 0,14. Outra técnica 
utilizada foi analisar os dados por meio da classe "andar" e quanto a biomecânica 
do movimento. Dessa forma foi possível eneteder padrões de parado,andando e correr.