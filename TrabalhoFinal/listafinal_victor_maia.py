# -*- coding: utf-8 -*-
"""ListaFinal_Victor_Maia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vTw2wyrCiOvocvHSDMMqzUqaEz4IVzY4

# Pré-Processamento
"""

!pip install plotly --upgrade

#Libs a serem instaladas
# pip install prettytable
#pip install plotly --upgrade

#Importação de Bibliotecas

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from IPython.display import Image
from prettytable import PrettyTable
import plotly.express as px
import seaborn as sns
import missingno as msno

#sklearn 
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
from sklearn.metrics import plot_confusion_matrix
from sklearn.model_selection import cross_val_score # Cross Validation Function.
from sklearn.model_selection import KFold # KFold Class.
from sklearn.model_selection import StratifiedKFold
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV


#importação excel
df=pd.read_excel("/content/drive/MyDrive/python/dataset-acelerometro.xlsx")

#visualizando o df
df.head()

"""## Exploração estátistica dos Dados"""

# Ordenação das colunas de x,y e z.
vetor=np.array(sorted(df['x']))
vetory=np.array(sorted(df['y']))
vetorz=np.array(sorted(df['z']))

data=[vetor,vetory,vetorz]

#Medidas Estátisticas, referente a coluna de X

media=np.mean(vetor)
mediana=np.median(vetor)
variancia=np.var(vetor)
desviopadrao=np.std(vetor)
coenficienteVariacao=(vetor.std()/vetor.mean())*100
primeiroQuartil=np.percentile(vetor,25)
segundoQuartil=np.percentile(vetor,50)
terceiroQuartil=np.percentile(vetor,75)
amplitudeInterquatilica=terceiroQuartil-primeiroQuartil

#Medidas Estátisticas, referente a coluna de y

mediay=np.mean(vetory)
medianay=np.median(vetory)
varianciay=np.var(vetory)
desviopadraoy=np.std(vetory)
coenficienteVariacaoy=(vetory.std()/vetory.mean())*100
primeiroQuartily=np.percentile(vetory,25)
segundoQuartily=np.percentile(vetory,50)
terceiroQuartily=np.percentile(vetory,75)
amplitudeInterquatilicay=terceiroQuartily-primeiroQuartily

#Medidas Estátisticas, referente a coluna de z

mediaz=np.mean(vetorz)
medianaz=np.median(vetorz)
varianciaz=np.var(vetorz)
desviopadraoz=np.std(vetorz)
coenficienteVariacaoz=(vetorz.std()/vetorz.mean())*100
primeiroQuartilz=np.percentile(vetorz,25)
segundoQuartilz=np.percentile(vetorz,50)
terceiroQuartilz=np.percentile(vetorz,75)
amplitudeInterquatilicaz=terceiroQuartilz-primeiroQuartilz


#Tabela com as informações Estátisticas, obtidas com o numpy 

print("\t\t\tExploração Estatística\n")
tabela = PrettyTable()

tabela.add_column('Medidas Estatísticas', ["Media", "Mediana", "Variancia", 
"Desvio Padrão", "Coeficiente de Variação", "Q1", "Q2","Q3","AI"])
tabela.add_column('X', [media, mediana,variancia, desviopadrao, 
coenficienteVariacao,primeiroQuartil,segundoQuartil,terceiroQuartil,amplitudeInterquatilica])
tabela.add_column('Y', [mediay, medianay,varianciay, desviopadraoy, 
coenficienteVariacaoy,primeiroQuartily,segundoQuartily,terceiroQuartily,amplitudeInterquatilicay])
tabela.add_column('Z', [mediaz, medianaz,varianciaz, desviopadraoz, 
coenficienteVariacaoz,primeiroQuartilz,segundoQuartilz,terceiroQuartilz,amplitudeInterquatilicaz])

print(tabela)

# Informações estatísticas básicas do dataframe (media, desvio padrão, maximo, minimo)

df.describe( )

#Exploração básica do dataframe

df[df['x']>=19.612701]

df[df['y']<=-6.002862]

df[df['z']>=16.393099]



"""## Validação dos dados"""

np.unique(df['movimento'],return_counts=True)

#contagem de registro em cada uma das classes
sns.countplot(x=df['movimento']);

#distribuição de x

plt.hist(x=df['x']);

#distribuição de y

plt.hist(x=df['y']);

#distribuição de z

plt.hist(x=df['z']);

#dispersão das dimensões em relação ao movimento praticado

grafico = px.scatter_matrix(df, dimensions=['x','y','z'],  color=df.movimento)
grafico.show()

"""## Tratamento de Valores Faltantes """

df.isnull().sum()

# Commented out IPython magic to ensure Python compatibility.

# %matplotlib inline
msno.matrix(df);

"""## Tratamento de Outliers"""

#Tratamento dos Outliers para os valores de X

#Calculando os Quartis
percentile25 = df['x'].quantile(0.25)
percentile75 = df['x'].quantile(0.75)

#Amplitude Interquartílica

iqr=percentile75-percentile25

#Limite superior e Limite inferior
upper_limit = percentile75 + 1.5 * iqr
lower_limit = percentile25 - 1.5 * iqr

#Buscando os Outliers
df[df['x'] > upper_limit]
df[df['x'] < lower_limit]

#aparando os dados
new_df = df[df['x'] < upper_limit]
new_df_cap = df.copy()
new_df_cap['x'] = np.where(
    new_df_cap['x'] > upper_limit,
    upper_limit,
    np.where(
        new_df_cap['x'] < lower_limit,
        lower_limit,
        new_df_cap['x']
    )
)

#Tratamento dos Outliers para os valores de y

#Calculando os Quartis
percentiley25 = df['y'].quantile(0.25)
percentiley75 = df['y'].quantile(0.75)

#Amplitude Interquartílica y

iqry=percentiley75-percentiley25

#Limite superior e Limite inferior
upper_limity = percentiley75 + 1.5 * iqry
lower_limity = percentiley25 - 1.5 * iqry

#Buscando os Outliers
df[df['y'] > upper_limity]
df[df['y'] < lower_limity]

#aparando os dados

new_dfy = df[df['y'] < upper_limity]

new_df_capy = df.copy()
new_df_capy['y'] = np.where(
    new_df_capy['y'] > upper_limity,
    upper_limity,
    np.where(
        new_df_capy['y'] < lower_limity,
        lower_limity,
        new_df_capy['y']
    )
)

#Tratamento dos Outliers para os valores de z

#Calculando os Quartis
percentilez25 = df['z'].quantile(0.25)
percentilez75 = df['z'].quantile(0.75)

#Amplitude Interquartílica

iqrz=percentilez75-percentilez25

#Limite superior e Limite inferior
upper_limitz = percentilez75 + 1.5 * iqrz
lower_limitz = percentilez25 - 1.5 * iqrz

#Buscando os Outliers
df[df['z'] > upper_limitz]
df[df['z'] < lower_limitz]

new_dfz = df[df['z'] < upper_limitz]

new_df_capz = df.copy()
new_df_capz['z'] = np.where(
    new_df_capz['z'] > upper_limitz,
    upper_limitz,
    np.where(
        new_df_capz['z'] < lower_limitz,
        lower_limitz,
        new_df_capz['z']
    )
)

xOutliers=new_df_cap['x']
yOutliers=new_df_capy['y']
zOutliers=new_df_capz['z']
outliers_tratados=[xOutliers,yOutliers,zOutliers]
plt.boxplot(outliers_tratados)
plt.xticks([1, 2, 3], ['x', 'y', 'z'])
plt.show()

#Data final, com os tratamentos feitos

indice=df['indice']
Tempo=df['Tempo']
Sensor=df['Sensor']
movimento=df['movimento']

df_acelerometro = pd.DataFrame(list(zip(indice,xOutliers,yOutliers,zOutliers,Tempo,Sensor,movimento)),columns=['indice','x', 'y', 'z','Tempo','Sensor','movimento'])
df_acelerometro

"""# Classificação

## KNN - n_neighbors 3,5 e 100
"""

# n_neighbors 3,5,100

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)

knn3 = KNeighborsClassifier(n_neighbors = 3)
knn3.fit(X_train, y_train)
print("KNN accuracy no teste: ", knn3.score(X_test, y_test))

knn5 = KNeighborsClassifier(n_neighbors = 5)
knn5.fit(X_train, y_train)
print("KNN accuracy no teste: ", knn5.score(X_test, y_test))

knn100 = KNeighborsClassifier(n_neighbors = 100)
knn100.fit(X_train, y_train)
print("KNN accuracy no teste: ", knn100.score(X_test, y_test))

pd.crosstab(y, knn5.predict(X), colnames=['Classificação'])

#Matriz confunsão

plot_confusion_matrix(knn5, X, y,values_format='d',cmap=plt.cm.Blues);

# Informações de Classificação

y_pred = knn5.predict(X_test)
print("Relatório de classificação: \n", classification_report(y_test, y_pred))

"""## KNN - n_neighbors 3,5,10 utilizando janela (10)




"""

rolling = df_acelerometro.rolling(window=10)
rolling_mean = rolling.mean()
rolling_mean = rolling_mean.dropna()

X = rolling_mean[['x', 'y', 'z']]
y = rolling_mean.movimento.astype(int)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

knn3 = KNeighborsClassifier(n_neighbors = 3)
knn3.fit(X_train, y_train)
print("KNN accuracy no teste: ", knn3.score(X_test, y_test))

knn5 = KNeighborsClassifier(n_neighbors = 5)
knn5.fit(X_train, y_train)
print("KNN accuracy no teste: ", knn5.score(X_test, y_test))

knn100 = KNeighborsClassifier(n_neighbors = 100)
knn100.fit(X_train, y_train)
print("KNN accuracy no teste: ", knn100.score(X_test, y_test))

pd.crosstab(y, knn5.predict(X), colnames=['Classificação'])

#Matriz confunsão

plot_confusion_matrix(knn5, X, y,values_format='d',cmap=plt.cm.Blues);

# Informações de Classificação

y_pred = knn5.predict(X_test)
print("Relatório de classificação: \n", classification_report(y_test, y_pred))

"""##SVC (Support Vector Machines) 3,5 e 100"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)

svc3 = SVC(C=3, gamma=0.1).fit(X_train, y_train)
svc3.score(X_test, y_test)

y_pred = svc3.predict(X_test)
print("SVC - acurácia com parametro C = '3': ", svc3.score(X_test, y_test))

svc5 = SVC(C=5, gamma=0.1).fit(X_train, y_train)
svc5.score(X_test, y_test)

y_pred = svc5.predict(X_test)
print("SVC - acurácia com parametro C = '5': ", svc5.score(X_test, y_test))

svc100 = SVC(C=100, gamma=0.1).fit(X_train, y_train)
svc100.score(X_test, y_test)

y_pred = svc100.predict(X_test)
print("SVC - acurácia com parametro C = '100': ", svc100.score(X_test, y_test))

plot_confusion_matrix(svc100, X_test, y_test, values_format = 'd',cmap=plt.cm.Blues)

y_pred = svc100.predict(X_test)

print("Classificação da melhor acurácia: \n",classification_report(y_test, y_pred))

"""## Random Forest 3,5,10"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)

# numero de arvores igual a 3
rf3 = RandomForestClassifier(n_estimators=3,random_state=0).fit(X_train, y_train)

print("RF - acurácia para n_estimators= 3: ", rf3.score(X_test, y_test))

# numero de arvores igual a 5
rf5 = RandomForestClassifier(n_estimators=5,random_state=0).fit(X_train, y_train)

print("RF - acurácia para n_estimators= 5: ", rf5.score(X_test, y_test))

# numero de arvores igual a 100
rf100 = RandomForestClassifier(n_estimators=100,random_state=0).fit(X_train, y_train)

print("RF - acurácia para n_estimators= 100: ", rf100.score(X_test, y_test))

plot_confusion_matrix(rf100, X_test, y_test, values_format = 'd',cmap=plt.cm.Blues);

y_pred = rf100.predict(X_test)

print("classificação da melhor acurácia: \n",classification_report(y_test, y_pred))

"""## Naive Bayes - Utilizando Teste(1/3)/Treino(2/3)"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,train_size=0.6,random_state=0)

naive_acelerometro=GaussianNB()
#Criação da Tabela de Probabilidade
naive_acelerometro.fit(X_train,y_train)
y_pred=naive_acelerometro.predict(X_test)

#registro por classe
naive_acelerometro.class_count_

resultado=naive_acelerometro.class_prior_

print(f'Andando_leve:{resultado[0]*100:,.2f}%')
print(f'Andando_moderado:{resultado[1]*100:,.2f}%')
print(f'Andando_vigoroso:{resultado[2]*100:,.2f}%')
print(f'Deitado_leve:{resultado[3]*100:,.2f}%')
print(f'Deitado_Moderado:{resultado[4]*100:,.2f}%')
print(f'Deitado_vigoroso:{resultado[5]*100:,.2f}%')
print(f'Sentado_leve:{resultado[6]*100:,.2f}%')
print(f'Sentado_Moderado:{resultado[7]*100:,.2f}%')
print(f'Sentado_vigoroso:{resultado[8]*100:,.2f}%')

plot_confusion_matrix(naive_acelerometro, X_test, y_test,values_format = 'd',cmap=plt.cm.Blues);

#Predict the response for test dataset
y_pred = naive_acelerometro.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

"""## Naive Bayes - Utilizando Teste(1/4)/Treino(2/3)"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,train_size=0.75,random_state=0)

naive_acelerometro2=GaussianNB()
#Criação da Tabela de Probabilidade
naive_acelerometro2.fit(X_train,y_train)
y_pred=naive_acelerometro2.predict(X_test)

#registro por classe
naive_acelerometro2.class_count_

resultado2=naive_acelerometro2.class_prior_

print(f'Andando_leve:{resultado2[0]*100:,.2f}%')
print(f'Andando_moderado:{resultado2[1]*100:,.2f}%')
print(f'Andando_vigoroso:{resultado2[2]*100:,.2f}%')
print(f'Deitado_leve:{resultado2[3]*100:,.2f}%')
print(f'Deitado_Moderado:{resultado2[4]*100:,.2f}%')
print(f'Deitado_vigoroso:{resultado2[5]*100:,.2f}%')
print(f'Sentado_leve:{resultado2[6]*100:,.2f}%')
print(f'Sentado_Moderado:{resultado2[7]*100:,.2f}%')
print(f'Sentado_vigoroso:{resultado2[8]*100:,.2f}%')

plot_confusion_matrix(naive_acelerometro2, X_test, y_test,values_format = 'd',cmap=plt.cm.Blues);

#Predict the response for test dataset
y_pred = naive_acelerometro.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

"""##  Validação Cruzada"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)

#treinamento do algoritmo

naive_acelerometrovalidacao_cruzada=GaussianNB()

#criação da Tabela de probabilidade
naive_acelerometrovalidacao_cruzada.fit(X_train, y_train)

y_pred = naive_acelerometrovalidacao_cruzada.predict(X_test)

#registro por classe 
naive_acelerometrovalidacao_cruzada.class_count_

prob=naive_acelerometrovalidacao_cruzada.class_prior_

print(f'Andando_leve:{prob[0]*100:,.2f}%')
print(f'Andando_moderado:{prob[1]*100:,.2f}%')
print(f'Andando_vigoroso:{prob[2]*100:,.2f}%')
print(f'Deitado_leve:{prob[3]*100:,.2f}%')
print(f'Deitado_Moderado:{prob[4]*100:,.2f}%')
print(f'Deitado_vigoroso:{prob[5]*100:,.2f}%')
print(f'Sentado_leve:{prob[6]*100:,.2f}%')
print(f'Sentado_Moderado:{prob[7]*100:,.2f}%')
print(f'Sentado_vigoroso:{prob[8]*100:,.2f}%')

"""### Validação Cruzada k->5"""

kfold  = KFold(n_splits=5, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_acelerometrovalidacao_cruzada,X_test, y_test, cv=kfold)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

resultvalidacao=np.mean(cv_scores)

"""### Validação Cruzada k->10"""

kfold  = KFold(n_splits=10, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_acelerometrovalidacao_cruzada,X_test, y_test, cv=kfold)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

"""## Naive Bayes - Teste(1/3)/Treino(2/3) - Estratificado"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,train_size=0.6,random_state=0,stratify=y)

naive_acelerometro=GaussianNB()
#Criação da Tabela de Probabilidade
naive_acelerometro.fit(X_train,y_train)
y_pred=naive_acelerometro.predict(X_test)

#registro por classe
naive_acelerometro.class_count_

resultado=naive_acelerometro.class_prior_

print(f'Andando_leve:{resultado[0]*100:,.2f}%')
print(f'Andando_moderado:{resultado[1]*100:,.2f}%')
print(f'Andando_vigoroso:{resultado[2]*100:,.2f}%')
print(f'Deitado_leve:{resultado[3]*100:,.2f}%')
print(f'Deitado_Moderado:{resultado[4]*100:,.2f}%')
print(f'Deitado_vigoroso:{resultado[5]*100:,.2f}%')
print(f'Sentado_leve:{resultado[6]*100:,.2f}%')
print(f'Sentado_Moderado:{resultado[7]*100:,.2f}%')
print(f'Sentado_vigoroso:{resultado[8]*100:,.2f}%')

#Predict the response for test dataset
y_pred = naive_acelerometro.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

"""## Naive Bayes - Teste(1/4)/Treino(3/4)- Estratificado"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,train_size=0.75,random_state=0,stratify=y)

naive_acelerometro2=GaussianNB()
#Criação da Tabela de Probabilidade
naive_acelerometro2.fit(X_train,y_train)
y_pred=naive_acelerometro2.predict(X_test)

#registro por classe
naive_acelerometro2.class_count_

resultado2=naive_acelerometro2.class_prior_

print(f'Andando_leve:{resultado2[0]*100:,.2f}%')
print(f'Andando_moderado:{resultado2[1]*100:,.2f}%')
print(f'Andando_vigoroso:{resultado2[2]*100:,.2f}%')
print(f'Deitado_leve:{resultado2[3]*100:,.2f}%')
print(f'Deitado_Moderado:{resultado2[4]*100:,.2f}%')
print(f'Deitado_vigoroso:{resultado2[5]*100:,.2f}%')
print(f'Sentado_leve:{resultado2[6]*100:,.2f}%')
print(f'Sentado_Moderado:{resultado2[7]*100:,.2f}%')
print(f'Sentado_vigoroso:{resultado2[8]*100:,.2f}%')

#Predict the response for test dataset
y_pred = naive_acelerometro.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred))

"""## Validação Cruzada Estratificada - K5"""

SKFold1  = StratifiedKFold(n_splits=5, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_acelerometrovalidacao_cruzada,X_test, y_test, cv=SKFold1)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

"""## Validação Cruzada Estratificada - K10"""

SKFold2  = StratifiedKFold(n_splits=10, shuffle=True) # shuffle=True, Shuffle (embaralhar) the data.
cv_scores = cross_val_score(naive_acelerometrovalidacao_cruzada,X_test, y_test, cv=SKFold2)

print('Mean cross-validation score: {:.3f}'.format(np.mean(cv_scores)))

validacaocruzadaestra=np.mean(cv_scores)

"""## Árvore de Decisão

### Utilizando teste(1/4) e treino (2/4)
"""

X = df_acelerometro[['x', 'y', 'z']]
y = df_acelerometro['movimento']
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,train_size=0.75,random_state=0)

modelDT = tree.DecisionTreeClassifier(criterion="entropy", min_samples_split=35,max_depth=4)
modelDT = modelDT.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = modelDT.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print(metrics.classification_report(y_test,y_pred));

plot_confusion_matrix(modelDT, X_test, y_test,values_format='d',cmap=plt.cm.Blues);

"""## Tuning de parâmetros com Grid Search"""

parametros = {'criterion':['gini','entropy'],'splitter':['best','random'],
'min_samples_split':[2,5,10],'min_samples_leaf':[1,5,10]}

grid = GridSearchCV(DecisionTreeClassifier(), param_grid=parametros, cv=5)
grid.fit(X_train, y_train)

melhores_parametros=grid.best_params_
melhor_resultado=grid.best_score_
print(melhores_parametros)
print(melhor_resultado)